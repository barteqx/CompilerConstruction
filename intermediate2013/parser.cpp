
// Parser generated by Maphoon 2008


#line 1


// Non-terminal symbols:





















#include "token.h"
#include "tokenizer.h"
#include "parser.h"

#include <cstdlib>




// Code generated by Maphoon 2008C
// Written by Hans de Nivelle, June 2008 - May 2010
// See the licence that was included with the code. 



namespace
{
   struct refused
   {
   };

   std::ostream& operator << ( std::ostream& stream, refused ref )
   {
      stream << "REFUSED";
      return stream;
   }
}



namespace
{

// Here come the tables:

   unsigned int starts [] = 
   {
      0, 38, 43, 46, 64, 70, 78, 80, 82, 84, 86, 
      88, 93, 96, 111, 114, 123, 130, 133, 136, 149, 
      153, 156, 159, 162, 164, 167, 170, 173, 177, 181, 
      183, 185, 187, 189, 191, 193, 197, 199, 203, 205, 
      207, 209, 211, 213, 216, 219, 224, 228, 231, 236, 
      239, 242, 245, 248, 251, 254, 257, 264, 271, 278, 
      281, 284, 286, 289, 292, 294, 297, 300, 305, 0 };

   unsigned int defaults [] = {
      0, 1, 2, 3, 3, 0, 0, 3, 3, 3, 10, 
      11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 
      21, 22, 23, 10, 25, 26, 27, 0, 5, 5, 
      5, 5, 5, 5, 5, 4, 36, 36, 4, 4, 
      0, 42, 43, 44, 45, 46, 47, 48, 49, 50, 
      51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 
      61, 10, 63, 64, 0, 66, 67, 68, 0 };

   int parsetable [] = 
   {
      tkn_IDENTIFIER, 10001, 
      tkn_NUMBER, 10002, 
      tkn_TIMES, 10003, 
      tkn_MINUS, 10004, 
      tkn_NOT, 10005, 
      tkn_LPAR, 10006, 
      tkn_ADDRESSOF, 10007, 
      tkn_PLUSPLUS, 10008, 
      tkn_MINUSMINUS, 10009, 
      tkn_B1, 10010, 
      tkn_B2, 10011, 
      tkn_B3, 10012, 
      tkn_B4, 10013, 
      tkn_A1, 10014, 
      tkn_N1, 10015, 
      tkn_N2, 10016, 
      tkn_N3, 10017, 
      tkn_E1, 10018, 
      tkn_E2, 10019, 
      tkn__defaultred, -10034, 0, 
      tkn_LPAR, 10020, 
      tkn__defaultred, -10033, 0, 
      tkn_IDENTIFIER, 10001, 
      tkn_NUMBER, 10002, 
      tkn_TIMES, 10003, 
      tkn_LPAR, 10006, 
      tkn_ADDRESSOF, 10007, 
      tkn_PLUSPLUS, 10008, 
      tkn_MINUSMINUS, 10009, 
      tkn_E1, 10021, 
      tkn_E2, 10019, 
      tkn_MINUS, 10004, 
      tkn_N3, 10022, 
      tkn_E1, 10018, 
      tkn_B1, 0, 
      tkn_B2, 0, 
      tkn_B3, 0, 
      tkn_B4, 10023, 
      tkn_B1, 10024, 
      tkn_E1, 10025, 
      tkn_E1, 10026, 
      tkn_E1, 10027, 
      tkn_OR, 10028, 
      tkn__defaultred, -10000, 0, 
      tkn_AND, 10029, 
      tkn__defaultred, -10002, 0, 
      tkn__defaultred, -10004, 0, 
      tkn_EQUAL, 10030, 
      tkn_NOTEQUAL, 10031, 
      tkn_LESSTHAN, 10032, 
      tkn_GREATERTHAN, 10033, 
      tkn_LESSEQUALTHAN, 10034, 
      tkn_GREATEREQUALTHAN, 10035, 
      tkn__defaultred, -10011, 0, 
      tkn__defaultred, -10013, 0, 
      tkn_PLUS, 10036, 
      tkn_MINUS, 10037, 
      tkn_ASSIGN, 10038, 
      tkn__defaultred, -10015, 0, 
      tkn_TIMES, 10039, 
      tkn_DIVIDES, 10040, 
      tkn__defaultred, -10018, 0, 
      tkn__defaultred, -10021, 0, 
      tkn__defaultred, -10023, 0, 
      tkn_LSQPAR, 10041, 
      tkn_DOT, 10042, 
      tkn_ARROW, 10043, 
      tkn_PLUSPLUS, 10044, 
      tkn_MINUSMINUS, 10045, 
      tkn_B1, 10046, 
      tkn_FUNCARGS, 10047, 
      tkn__defaultred, -10025, 0, 
      tkn__defaultred, -10022, 0, 
      tkn__defaultred, -10012, 0, 
      tkn_RPAR, 10048, 
      tkn__defaultred, -10024, 0, 
      tkn__defaultred, -10026, 0, 
      tkn__defaultred, -10027, 0, 
      tkn_B1, 0, 
      tkn_B2, 10049, 
      tkn_B3, 10050, 
      tkn_B4, 10013, 
      tkn_B4, 10051, 
      tkn_B4, 10052, 
      tkn_B4, 10053, 
      tkn_B4, 10054, 
      tkn_B4, 10055, 
      tkn_B4, 10056, 
      tkn_N2, 10057, 
      tkn_N3, 10017, 
      tkn_N2, 10058, 
      tkn_N1, 10059, 
      tkn_N2, 10016, 
      tkn_N3, 10060, 
      tkn_N3, 10061, 
      tkn_B1, 10062, 
      tkn_IDENTIFIER, 10063, 
      tkn_IDENTIFIER, 10064, 
      tkn__defaultred, -10031, 0, 
      tkn__defaultred, -10032, 0, 
      tkn__defaultred, -10037, 0, 
      tkn_OR, 10028, 
      tkn_COMMA, 10065, 
      tkn_RPAR, 10066, 
      tkn__defaultred, -10035, 0, 
      tkn__defaultred, -10001, 0, 
      tkn_AND, 10029, 
      tkn__defaultred, -10003, 0, 
      tkn__defaultred, -10009, 0, 
      tkn__defaultred, -10010, 0, 
      tkn__defaultred, -10005, 0, 
      tkn__defaultred, -10007, 0, 
      tkn__defaultred, -10006, 0, 
      tkn__defaultred, -10008, 0, 
      tkn__defaultred, -10016, 0, 
      tkn_TIMES, 10039, 
      tkn_DIVIDES, 10040, 
      tkn__defaultred, -10017, 0, 
      tkn_TIMES, 10039, 
      tkn_DIVIDES, 10040, 
      tkn__defaultred, -10014, 0, 
      tkn_PLUS, 10036, 
      tkn_MINUS, 10037, 
      tkn__defaultred, -10019, 0, 
      tkn__defaultred, -10020, 0, 
      tkn_RSQPAR, 10067, 
      tkn__defaultred, -10028, 0, 
      tkn__defaultred, -10029, 0, 
      tkn_B1, 10068, 
      tkn__defaultred, -10036, 0, 
      tkn__defaultred, -10030, 0, 
      tkn__defaultred, -10038, 0, 
      tkn_OR, 10028, 
   0 };

   int entrypoints [] = 
   {
      tkn_B1, 0, tkn_SEMICOLON, -1,
      -1
   };



}


namespace
{


   // There are two reduce functions.
   // 
   // The first returns a token from the parse stack.
   // The other tokens are removed, and it is checked that the
   // token has the right type.
   // 
   // The second returns a new token. All tokens from the parse stack
   // are removed, and the new token is pushed.

   void reduce( std::list< token > & parsestack,
                std::list< token > :: iterator position,
                tokentype expectedtype,
                std::list< token > :: const_iterator result )
   {
      ASSERT( result -> type == expectedtype );
         // Must be type of lhs. 
      ASSERT( result -> iswellformed( ));

      bool seen = false;
      while( position != parsestack. end( ))
      {
         if( position == result )
         {
            ASSERT( !seen );
            seen = true;
            ++ position;
         }
         else
         {
            std::list< token > :: iterator p1 = position;
            ++ position; 
            parsestack. erase( p1 );
         }
      }
      ASSERT( seen );
   }


   void reduce( std::list< token > & parsestack,
                std::list< token > :: iterator position,
                tokentype expectedtype,
                const token& result )
   {
      ASSERT( result. type == expectedtype ); 
      ASSERT( result. iswellformed( )); 

      while( position != parsestack. end( ))
      {
         ASSERT( & (*position) != & result );
            // If this happenes, the user typed 'return *T'
            // for an attribute variable. 
            // He should have typed 'return T' instead. 
  
         std::list< token > :: iterator p1 = position;
         ++ position;
         parsestack. erase( p1 ); 
      }

      parsestack. insert( position, result ); 
   }


   // This is not terribly efficient, but we expect the size of the
   // rules to be moderate.

   std::list< token > :: iterator 
   operator - ( std::list< token > :: iterator p,
                unsigned int diff )
   {
      while( diff > 0 )
      {
         -- diff; 
         -- p;
      }
      return p; 
   }


// Here come the actions:

void reduction_0(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B21 ) throw( refused )
{

#line 52 "parser.m"


B21 -> type = tkn_B1;
{ reduce( stack, position, tkn_B1, B21 ); return; }

{ reduce( stack, position, tkn_B1, tkn_B1 ); return; }

}


void reduction_1(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B11,
   std::list < token > :: iterator OR2,
   std::list < token > :: iterator B23 ) throw( refused )
{

#line 57 "parser.m"


token t = tkn_B1;
t. ct. push_back( ctree( identifier( "infix||" ),
{ B11 -> ct. front( ),
B23 -> ct. front( ) } ));
{ reduce( stack, position, tkn_B1, t ); return; }

{ reduce( stack, position, tkn_B1, tkn_B1 ); return; }

}


void reduction_2(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B31 ) throw( refused )
{

#line 67 "parser.m"


B31 -> type = tkn_B2;
{ reduce( stack, position, tkn_B2, B31 ); return; }

{ reduce( stack, position, tkn_B2, tkn_B2 ); return; }

}


void reduction_3(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B21,
   std::list < token > :: iterator AND2,
   std::list < token > :: iterator B33 ) throw( refused )
{

#line 72 "parser.m"


token t = tkn_B2;
t. ct. push_back( ctree( identifier( "infix&&" ),
{ B21 -> ct. front( ),
B33 -> ct. front( ) } ));
{ reduce( stack, position, tkn_B2, t ); return; }

{ reduce( stack, position, tkn_B2, tkn_B2 ); return; }

}


void reduction_4(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B41 ) throw( refused )
{

#line 82 "parser.m"


B41 -> type = tkn_B3;
{ reduce( stack, position, tkn_B3, B41 ); return; }

{ reduce( stack, position, tkn_B3, tkn_B3 ); return; }

}


void reduction_5(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B41,
   std::list < token > :: iterator LESSTHAN2,
   std::list < token > :: iterator B43 ) throw( refused )
{

#line 87 "parser.m"


token t = tkn_B3;
t. ct. push_back( ctree( identifier( "infix<" ),
{ B41 -> ct. front( ),
B43 -> ct. front( ) } ));
{ reduce( stack, position, tkn_B3, t ); return; }

{ reduce( stack, position, tkn_B3, tkn_B3 ); return; }

}


void reduction_6(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B41,
   std::list < token > :: iterator LESSEQUALTHAN2,
   std::list < token > :: iterator B43 ) throw( refused )
{

#line 95 "parser.m"


token t = tkn_B3;
t. ct. push_back( ctree( identifier( "infix<=" ),
{ B41 -> ct. front( ),
B43 -> ct. front( ) } ));
{ reduce( stack, position, tkn_B3, t ); return; }

{ reduce( stack, position, tkn_B3, tkn_B3 ); return; }

}


void reduction_7(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B41,
   std::list < token > :: iterator GREATERTHAN2,
   std::list < token > :: iterator B43 ) throw( refused )
{

#line 103 "parser.m"


token t = tkn_B3;
t. ct. push_back( ctree( identifier( "infix>" ),
{ B41 -> ct. front( ),
B43 -> ct. front( ) } ));
{ reduce( stack, position, tkn_B3, t ); return; }

{ reduce( stack, position, tkn_B3, tkn_B3 ); return; }

}


void reduction_8(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B41,
   std::list < token > :: iterator GREATEREQUALTHAN2,
   std::list < token > :: iterator B43 ) throw( refused )
{

#line 111 "parser.m"


token t = tkn_B3;
t. ct. push_back( ctree( identifier( "infix>=" ),
{ B41 -> ct. front( ),
B43 -> ct. front( ) } ));
{ reduce( stack, position, tkn_B3, t ); return; }

{ reduce( stack, position, tkn_B3, tkn_B3 ); return; }

}


void reduction_9(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B41,
   std::list < token > :: iterator EQUAL2,
   std::list < token > :: iterator B43 ) throw( refused )
{

#line 119 "parser.m"


token t = tkn_B3;
t. ct. push_back( ctree( identifier( "infix==" ),
{ B41 -> ct. front( ),
B43 -> ct. front( ) } ));
{ reduce( stack, position, tkn_B3, t ); return; }

{ reduce( stack, position, tkn_B3, tkn_B3 ); return; }

}


void reduction_10(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B41,
   std::list < token > :: iterator NOTEQUAL2,
   std::list < token > :: iterator B43 ) throw( refused )
{

#line 127 "parser.m"


token t = tkn_B4;
t. ct. push_back( ctree( identifier( "infix!=" ),
{ B41 -> ct. front( ),
B43 -> ct. front( ) } ));
{ reduce( stack, position, tkn_B3, t ); return; }

{ reduce( stack, position, tkn_B3, tkn_B3 ); return; }

}


void reduction_11(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator A11 ) throw( refused )
{

#line 137 "parser.m"


A11 -> type = tkn_B4;
{ reduce( stack, position, tkn_B4, A11 ); return; }

{ reduce( stack, position, tkn_B4, tkn_B4 ); return; }

}


void reduction_12(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator NOT1,
   std::list < token > :: iterator B42 ) throw( refused )
{

#line 142 "parser.m"


token t = tkn_B4;
t. ct. push_back( ctree( identifier( "infix!" ),
{ B42 -> ct. front( ) } ));
{ reduce( stack, position, tkn_B4, t ); return; }

{ reduce( stack, position, tkn_B4, tkn_B4 ); return; }

}


void reduction_13(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator N11 ) throw( refused )
{

#line 151 "parser.m"


N11 -> type = tkn_A1;
{ reduce( stack, position, tkn_A1, N11 ); return; }

{ reduce( stack, position, tkn_A1, tkn_A1 ); return; }

}


void reduction_14(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator N11,
   std::list < token > :: iterator ASSIGN2,
   std::list < token > :: iterator N13 ) throw( refused )
{

#line 156 "parser.m"


token t = tkn_A1;
t. ct. push_back( ctree( identifier( "infix=" ),
{ N11 -> ct. front( ),
N13 -> ct. front( ) } ));
{ reduce( stack, position, tkn_A1, t ); return; }

{ reduce( stack, position, tkn_A1, tkn_A1 ); return; }

}


void reduction_15(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator N21 ) throw( refused )
{

#line 166 "parser.m"


N21 -> type = tkn_N1;
{ reduce( stack, position, tkn_N1, N21 ); return; }

{ reduce( stack, position, tkn_N1, tkn_N1 ); return; }

}


void reduction_16(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator N11,
   std::list < token > :: iterator PLUS2,
   std::list < token > :: iterator N23 ) throw( refused )
{

#line 171 "parser.m"


token t = tkn_N1;
t. ct. push_back( ctree( identifier( "infix+" ),
{ N11 -> ct. front( ),
N23 -> ct. front( ) } ));
{ reduce( stack, position, tkn_N1, t ); return; }

{ reduce( stack, position, tkn_N1, tkn_N1 ); return; }

}


void reduction_17(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator N11,
   std::list < token > :: iterator MINUS2,
   std::list < token > :: iterator N23 ) throw( refused )
{

#line 179 "parser.m"


token t = tkn_N1;
t. ct. push_back( ctree( identifier( "infix-" ),
{ N11 -> ct. front( ),
N23 -> ct. front( ) } ));
{ reduce( stack, position, tkn_N1, t ); return; }

{ reduce( stack, position, tkn_N1, tkn_N1 ); return; }

}


void reduction_18(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator N31 ) throw( refused )
{

#line 189 "parser.m"


N31 -> type = tkn_N2;
{ reduce( stack, position, tkn_N2, N31 ); return; }

{ reduce( stack, position, tkn_N2, tkn_N2 ); return; }

}


void reduction_19(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator N21,
   std::list < token > :: iterator TIMES2,
   std::list < token > :: iterator N33 ) throw( refused )
{

#line 194 "parser.m"


token t = tkn_N2;
t. ct. push_back( ctree( identifier( "infix*" ),
{ N21 -> ct. front( ), N33 -> ct. front( ) } ));
{ reduce( stack, position, tkn_N2, t ); return; }

{ reduce( stack, position, tkn_N2, tkn_N2 ); return; }

}


void reduction_20(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator N21,
   std::list < token > :: iterator DIVIDES2,
   std::list < token > :: iterator N33 ) throw( refused )
{

#line 201 "parser.m"


token t = tkn_N2;
t. ct. push_back( ctree( identifier( "infix/" ),
{ N21 -> ct. front( ), N33 -> ct. front( ) } ));
{ reduce( stack, position, tkn_N2, t ); return; }

{ reduce( stack, position, tkn_N2, tkn_N2 ); return; }

}


void reduction_21(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator E11 ) throw( refused )
{

#line 210 "parser.m"


E11 -> type = tkn_N3;
{ reduce( stack, position, tkn_N3, E11 ); return; }

{ reduce( stack, position, tkn_N3, tkn_N3 ); return; }

}


void reduction_22(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator MINUS1,
   std::list < token > :: iterator N32 ) throw( refused )
{

#line 215 "parser.m"


token t = tkn_N3;
t. ct. push_back( ctree( identifier( "prefix-" ),
{ N32 -> ct. front( ) } ));
{ reduce( stack, position, tkn_N3, t ); return; }

{ reduce( stack, position, tkn_N3, tkn_N3 ); return; }

}


void reduction_23(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator E21 ) throw( refused )
{

#line 224 "parser.m"


E21 -> type = tkn_E1;
{ reduce( stack, position, tkn_E1, E21 ); return; }

{ reduce( stack, position, tkn_E1, tkn_E1 ); return; }

}


void reduction_24(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator ADDRESSOF1,
   std::list < token > :: iterator E12 ) throw( refused )
{

#line 229 "parser.m"


token t = tkn_E1;
t. ct. push_back( ctree( identifier( "prefix&" ),
{ E12 -> ct. front( ) } ));
{ reduce( stack, position, tkn_E1, t ); return; }

{ reduce( stack, position, tkn_E1, tkn_E1 ); return; }

}


void reduction_25(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator TIMES1,
   std::list < token > :: iterator E12 ) throw( refused )
{

#line 236 "parser.m"


token t = tkn_E1;
t. ct. push_back( ctree( identifier( "prefix*" ),
{ E12 -> ct. front( ) } ));
{ reduce( stack, position, tkn_E1, t ); return; }

{ reduce( stack, position, tkn_E1, tkn_E1 ); return; }

}


void reduction_26(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator PLUSPLUS1,
   std::list < token > :: iterator E12 ) throw( refused )
{

#line 243 "parser.m"


token t = tkn_E1;
t. ct. push_back( ctree( identifier( "prefix++" ),
{ E12 -> ct. front( ) } ));
{ reduce( stack, position, tkn_E1, t ); return; }

{ reduce( stack, position, tkn_E1, tkn_E1 ); return; }

}


void reduction_27(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator MINUSMINUS1,
   std::list < token > :: iterator E12 ) throw( refused )
{

#line 250 "parser.m"


token t = tkn_E1;
t. ct. push_back( ctree( identifier( "prefix--" ),
{ E12 -> ct. front( ) } ));
{ reduce( stack, position, tkn_E1, t ); return; }

{ reduce( stack, position, tkn_E1, tkn_E1 ); return; }

}


void reduction_28(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator E21,
   std::list < token > :: iterator DOT2,
   std::list < token > :: iterator IDENTIFIER3 ) throw( refused )
{

#line 259 "parser.m"


token t = tkn_E2;
const ctree& ct = IDENTIFIER3 -> ct. front( );
ASSERT( ct. gettreetype( ) == treetype::var );

t. ct. push_back(
ctree(
identifier( { "fieldfunction" } ) + ct. getvarname( ),
{ E21 -> ct. front( ) } ));
{ reduce( stack, position, tkn_E2, t ); return; }

{ reduce( stack, position, tkn_E2, tkn_E2 ); return; }

}


void reduction_29(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator E21,
   std::list < token > :: iterator ARROW2,
   std::list < token > :: iterator IDENTIFIER3 ) throw( refused )
{

#line 271 "parser.m"


// It is an abbreviation for (*e). id

token t = tkn_E2;
const ctree& ct = IDENTIFIER3 -> ct. front( );
ASSERT( ct. gettreetype( ) == treetype::var );

t. ct. push_back(
ctree(
identifier( { "fieldfunction" } ) + ct. getvarname( ),
{ ctree( identifier( "prefix*" ),
{ E21 -> ct. front( ) } ) } ));
{ reduce( stack, position, tkn_E2, t ); return; }

{ reduce( stack, position, tkn_E2, tkn_E2 ); return; }

}


void reduction_30(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator E21,
   std::list < token > :: iterator LSQPAR2,
   std::list < token > :: iterator B13,
   std::list < token > :: iterator RSQPAR4 ) throw( refused )
{

#line 286 "parser.m"


// It is an abbreviation for *( E2 + B1 )

token t = tkn_E2;
t. ct. push_back( ctree( identifier( "prefix*" ),
{ ctree( identifier( "infix+" ),
{ E21 -> ct. front( ),
B13 -> ct. front( ) } ) } ));
{ reduce( stack, position, tkn_E2, t ); return; }

{ reduce( stack, position, tkn_E2, tkn_E2 ); return; }

}


void reduction_31(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator E21,
   std::list < token > :: iterator PLUSPLUS2 ) throw( refused )
{

#line 297 "parser.m"


token t = tkn_E2;
t. ct. push_back( ctree( identifier( "postfix++" ),
{ E21 -> ct. front( ) } ));
{ reduce( stack, position, tkn_E2, t ); return; }

{ reduce( stack, position, tkn_E2, tkn_E2 ); return; }

}


void reduction_32(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator E21,
   std::list < token > :: iterator MINUSMINUS2 ) throw( refused )
{

#line 304 "parser.m"


token t = tkn_E2;
t. ct. push_back( ctree( identifier( "postfix--" ),
{ E21 -> ct. front( ) } ));
{ reduce( stack, position, tkn_E2, t ); return; }

{ reduce( stack, position, tkn_E2, tkn_E2 ); return; }

}


void reduction_33(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator NUMBER1 ) throw( refused )
{

#line 311 "parser.m"


NUMBER1 -> type = tkn_E2;
{ reduce( stack, position, tkn_E2, NUMBER1 ); return; }

{ reduce( stack, position, tkn_E2, tkn_E2 ); return; }

}


void reduction_34(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator IDENTIFIER1 ) throw( refused )
{

#line 316 "parser.m"


IDENTIFIER1 -> type = tkn_E2;
{ reduce( stack, position, tkn_E2, IDENTIFIER1 ); return; }

{ reduce( stack, position, tkn_E2, tkn_E2 ); return; }

}


void reduction_35(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator LPAR1,
   std::list < token > :: iterator B12,
   std::list < token > :: iterator RPAR3 ) throw( refused )
{

#line 321 "parser.m"


B12 -> type = tkn_E2;
{ reduce( stack, position, tkn_E2, B12 ); return; }

{ reduce( stack, position, tkn_E2, tkn_E2 ); return; }

}


void reduction_36(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator IDENTIFIER1,
   std::list < token > :: iterator LPAR2,
   std::list < token > :: iterator FUNCARGS3,
   std::list < token > :: iterator RPAR4 ) throw( refused )
{

#line 326 "parser.m"


const ctree& id = IDENTIFIER1 -> ct. front( );
ASSERT( id. gettreetype( ) == treetype::var );
std::vector< ctree > args;
for( auto p = FUNCARGS3 -> ct. begin( );
p != FUNCARGS3 -> ct. end( );
++ p )
{
args. push_back( *p );
}

token t = tkn_E2;
t. ct. push_back( ctree( id. getvarname( ), args ));
{ reduce( stack, position, tkn_E2, t ); return; }

{ reduce( stack, position, tkn_E2, tkn_E2 ); return; }

}


void reduction_37(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator B11 ) throw( refused )
{

#line 344 "parser.m"


B11 -> type = tkn_FUNCARGS;
{ reduce( stack, position, tkn_FUNCARGS, B11 ); return; }

{ reduce( stack, position, tkn_FUNCARGS, tkn_FUNCARGS ); return; }

}


void reduction_38(
   std::list < token > & stack,
   std::list < token > :: iterator position,
   std::list < token > :: iterator FUNCARGS1,
   std::list < token > :: iterator COMMA2,
   std::list < token > :: iterator B13 ) throw( refused )
{

#line 349 "parser.m"


FUNCARGS1 -> ct. push_back( B13 -> ct. front( ));
{ reduce( stack, position, tkn_FUNCARGS, FUNCARGS1 ); return; }

{ reduce( stack, position, tkn_FUNCARGS, tkn_FUNCARGS ); return; }

}





   
   // The return values are specified as follows: 
   // 
   //                 0 : error.
   //        10000 + X  : push to state X.
   //        -10000 - X : Reduce rule X.
   // 
   // The returned list contains a sequence of reductions, terminated 
   // by an error or a push. 
   //
   // We try to base our decision on lookahead. If more lookahead
   // is required, we extend lookahead by doing: 
   //    lookahead. push_back( input. scan( ));
   

   std::list< int > decideaction( unsigned int ss, tokenizer& input )
   {
      std::list< int > result;

      unsigned int k = starts [ss];
      unsigned int defred = 0;
 
      while( true )
      {
         while( k == starts [ ss + 1 ] )
         {
            // This means that we reached the end.
            // If defaults [ss] != ss, we can continue looking in another
            // state.

            if( defaults [ss] == ss )
            {
               if( defred == 0 )
                  result. push_back(0);
               else
               {
                  result. push_back( defred ); 
                  result. push_back(0);
               }
               return result; 
            }

            ss = defaults [ ss ];
            k = starts [ ss ]; 
         }
          
         if( parsetable [k] == tkn__defaultred )
         {
            ASSERT( parsetable [ k+1 ] < 0 && parsetable [ k+2 ] == 0 );
            ASSERT( defred == 0 );
            defred = parsetable [ k + 1 ];
            k += 3; 
         }
         else
         {
            if( input. lookahead. size( ) == 0 )
            {
               input. scan( );
               ASSERT( input. lookahead. size( ));
               ASSERT( input. lookahead. back( ). iswellformed( ));
            }

            if( input. lookahead. size( ) &&
                input. lookahead. front( ). type == parsetable [k] )
            {
               ++ k; 
               while( parsetable [k] < 0 )
                  result. push_back( parsetable [ k ++ ] );
               result. push_back( parsetable [k] );
               return result;
            }
            
            ++ k;
            while( parsetable [k] < 0 )
               ++ k;
            ++ k; 
         }
      }
   }


   bool stateisempty( unsigned int ss )
   {
      return starts [ss] == starts [ss+1];
   }


   bool isstartlookahead( unsigned int entry, tokenizer& input )
   { 
      ASSERT( input. lookahead. size( ));

      entry += 2;  
      while( entrypoints [ entry ] >= 0 )
      {
         if( entrypoints [ entry ] == input. lookahead. front( ). type )
            return true;
         ++ entry;
      }
      return false;
   }

}
 

// The tokenizer must have the following features:
// It must have a field std::list< token > lookahead; 
// It must have a method void scan( ), which reads a token from somewhere
// and appends it to lookahead. scan( ) must always return a token,
// also when it reaches end of file, or when it is unable to read 
// input for some kind of reason. 
// It must have a method syntaxerror( ), which reports a syntax error
// to the user. 
// 
// The parser is called with the start symbol of the partial grammar
// that has to be parsed. 
// It uses the lookahead list of the tokenizer for returning its value.
// In case of a successful parse, lookahead starts with the start
// symbol. A second symbol need not be present. If there is a second
// symbol, then it is the lookahead symbol of the original start symbol. 
// The parser will read the lookahead only when it is necessary for
// deciding.
// 
// When an error occurred, and the parser reached a lookahead symbol
// while attempting to recover, the lookahead list equals this 
// lookahead symbol. 
// If the parser gave up, because more than
// recoverlength symbols were read, it returns a list of length 1 
// containing a recover symbol. 

// Setting recoverlength = 0 ensures that the parser will not try to
// recover. 


void parser( tokenizer& input, tokentype start, unsigned int recoverlength )
{

   unsigned int errorcount = 0;
      // If errorcount > 0, then errors are not reported. 
      // Instead we assume that the previous recovery was not 
      // successful. 

   unsigned int entry = 0;
   while( entrypoints [ entry ] != -1 && entrypoints [ entry ] != start )
   {
      while( entrypoints [ entry ] != -1 )
         ++ entry;
      ++ entry;
   }

   if( entrypoints [ entry ] != start )
   {
      std::cout<< "could not find startsymbol " << start << "\n";
      ASSERT( false ); 
      exit(0);
   }

   std::list< unsigned int > states; 
   states. push_back( entrypoints [ entry + 1 ] );

   std::list< token > parsestack; 
 
   while( true ) 
   {
      ASSERT( states. size( ) == parsestack. size( ) + 1 );

#ifdef MAPH_DEBUG
      std::cout << "stack of states: "; 
      for( std::list< unsigned int > :: const_iterator
              p = states. begin( );
              p != states. end( );
              ++ p )
      {
         if( p != states. begin( ))
            std::cout << ", "; 
         std::cout << *p;
      }
      std::cout << "\n";

      std::cout << "stack of symbols: "; 
      for( std::list< token > :: const_iterator
              p = parsestack. begin( );
              p != parsestack. end( );
              ++ p )
      {
         if( p != parsestack. begin( ))
            std::cout << ", ";
         std::cout << *p;
      }
      std::cout << "\n";

      if( input. lookahead. size( ))
         std::cout << "lookahead: " << input. lookahead. front( ) << "\n";
#endif
      // We will check if we are in an accepting state. 
      // The parse stack must have size 1, and contain the 
      // start symbol of the grammar.

      if( parsestack. size( ) == 1 && 
          parsestack. front( ). type == entrypoints [ entry ] )
      {
         // This is a good start.
      
         // If we are in an empty state, we simply accept, and that's
         // the end of the story.

         if( stateisempty( states. back( )))
         {
            input. lookahead. splice( input. lookahead. begin( ),
                                      parsestack, parsestack. begin( ));
            
            return;  
         }

         // Otherwise, we check whether lookahead is one of the 
         // lookahead symbols of the start symbol. 
                   
         if( input. lookahead. size( ) == 0 )
         {
            input. scan( );
            ASSERT( input. lookahead. size( ));
            ASSERT( input. lookahead. back( ). iswellformed( ));
         }

         if( isstartlookahead( entry, input )) 
         {
            // This means that we accept. We move the start symbol
            // to the lookahead and quit.

            input. lookahead. splice( input. lookahead. begin( ),
                                     parsestack, parsestack. begin( ));
            return; 
         }
 
         // Otherwise we simply continue, and let things go their way.
         // This does not necessarily imply that there will be an error.
         // It is also possible that the parser will continue.
      }
       
      std::list< int > actions = decideaction( states. back( ), input );

      // If we have reductions, we try to perform them:
      // If we manage to make a reduction, we clear actions,
      // so that we will come out of this loop:

      while( actions. size( ) > 1 ) 
      {
         ASSERT( actions. front( ) < 0 );
         unsigned int rule = - actions. front( ) - 10000;

#ifdef MAPH_DEBUG
         std::cout << "attempting to reduce rule " << rule << "\n";
#endif

         try
         {
            switch( rule ) 
            {
case 0:
   reduction_0( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 1:
   reduction_1( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 2:
   reduction_2( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 3:
   reduction_3( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 4:
   reduction_4( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 5:
   reduction_5( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 6:
   reduction_6( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 7:
   reduction_7( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 8:
   reduction_8( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 9:
   reduction_9( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 10:
   reduction_10( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 11:
   reduction_11( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 12:
   reduction_12( parsestack, parsestack. end( ) - 2, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 13:
   reduction_13( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 14:
   reduction_14( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 15:
   reduction_15( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 16:
   reduction_16( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 17:
   reduction_17( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 18:
   reduction_18( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 19:
   reduction_19( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 20:
   reduction_20( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 21:
   reduction_21( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 22:
   reduction_22( parsestack, parsestack. end( ) - 2, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 23:
   reduction_23( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 24:
   reduction_24( parsestack, parsestack. end( ) - 2, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 25:
   reduction_25( parsestack, parsestack. end( ) - 2, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 26:
   reduction_26( parsestack, parsestack. end( ) - 2, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 27:
   reduction_27( parsestack, parsestack. end( ) - 2, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 28:
   reduction_28( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 29:
   reduction_29( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 30:
   reduction_30( parsestack, parsestack. end( ) - 4, parsestack. end( ) - 4, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 31:
   reduction_31( parsestack, parsestack. end( ) - 2, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 32:
   reduction_32( parsestack, parsestack. end( ) - 2, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 33:
   reduction_33( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 34:
   reduction_34( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 35:
   reduction_35( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 36:
   reduction_36( parsestack, parsestack. end( ) - 4, parsestack. end( ) - 4, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;
case 37:
   reduction_37( parsestack, parsestack. end( ) - 1, parsestack. end( ) - 1 );
   break;
case 38:
   reduction_38( parsestack, parsestack. end( ) - 3, parsestack. end( ) - 3, parsestack. end( ) - 2, parsestack. end( ) - 1 );
   break;

            default:
	       std::cout << "unknown rule!\n";
	       exit(0); 
            }

#ifdef MAPH_DEBUG
            std::cout << "reduced rule " << rule << "\n";
#endif

            ASSERT( parsestack. size( )); 

            ASSERT( states. size( ) >= parsestack. size( ));

            while( states. size( ) > parsestack. size( ))
               states. pop_back( );

            // We now need to shift the lhs of the rule.
            // We do not like to copy tokens, because their attributes
            // can be big without borders. Copying can be avoided 
            // using list specific operations. 

            std::list< token > :: iterator p = parsestack. end( ) - 1;
            input. lookahead. splice( input. lookahead. begin( ), 
                                      parsestack, p );
               // Now the back of the parsestack is in front of lookahead.
               // It is possible that lookahead has a length of two now.

            actions = decideaction( states. back( ), input ); 

#if 0
            for( std::list< int > :: const_iterator
                     p = actions. begin( );
                     p != actions. end( );
                     ++ p )
            {
               std::cout << *p << "\n";
            }
#endif 

            // The action may contain reductions, but we are interested
            // in the push. In earlier versions, I assumed that actions 
            // necessarily contains only a single push, but this assumption
            // turned out wrong.  

            while( actions. size( ) > 1 )
            {
               ASSERT( actions. front( ) < 0 );
               actions. pop_front( );
            }

            // Now the action list should consist of a single push:

            ASSERT( actions. size( ) == 1 && actions. front( ) > 0 );

#ifdef MAPH_DEBUG
            std::cout << "goto " << actions. front( ) - 10000 << "\n"; 
#endif
            // We do not carry out the goto. 

            ++ errorcount;
         }
         catch( refused ref )
         {
#ifdef MAPH_DEBUG
            std::cout << "rule " << rule << " refused\n";
#endif
            actions. pop_front( );
               // We are not going to be sad about the refusal. We 
               // simply try the next in line.
         }
      }   
 
      if( actions. size( ) == 1 && actions. front( ) > 0 ) 
      {
         ASSERT( input. lookahead. size( ) == 1 || 
                 input. lookahead. size( ) == 2 );
         actions. front( ) -= 10000;
#ifdef MAPH_DEBUG
         std::cout << "shifting " << input. lookahead. front( ) << "\n"; 
#endif
 
         if( errorcount > 0 ) 
	    -- errorcount; 

         parsestack. splice( parsestack. end( ), 
                             input. lookahead, input. lookahead. begin( ));
            // This puts the symbol on the parsestack without moving it. 

         states. push_back( actions. front( ));

      }
      else
      {
         // If there is something left in actions, it is an error.

         ASSERT( actions. size( ) == 1 && actions. front( ) == 0 );
         ASSERT( input. lookahead. size( ));

#ifdef MAPH_DEBUG
        std::cout << "error!\n"; 
#endif

         // It is the responsability of the tokenizer to process the error:

         input. syntaxerror( );
 
         // Recovery will be the level at which we can recover.
         // As long as we did not recover, it will be -1.
 
         int recovery = -1; 
         unsigned int ignoredtokens = 0;

         while( recovery < 0 && ! isstartlookahead( entry, input ) && 
                ignoredtokens < recoverlength )
         {
            // Our approach is simple and inefficient, we look for
            // states that can push a recovery symbol, and after that
            // would be able to push the current lookahead symbol.

            std::list< unsigned int > :: const_iterator p = states. begin( );

            for( unsigned int k = 0; k < states. size( ); ++ k )
            {
               input. lookahead. push_front( token( tkn__recover ));
               actions = decideaction( *p, input );
               input. lookahead. pop_front( );

               if( actions. size( ) == 1 && actions. front( ) > 0 )
               {
                  // Recover transition is possible. 

                  unsigned int trans = actions. front( ) - 10000; 
                  actions = decideaction( trans, input );
               
                  if( actions. size( ) == 1 && actions. front( ) > 0 )
                     recovery = k;
                        // We remember that recovery was possible.
                        // If more than recovery is possible, we will
                        // remember the highest in recovery. 
               }
            
               ++ p;
            }
       
            if( recovery < 0 )
            {
               input. lookahead. clear( );
               ++ ignoredtokens;
               input. scan( );
               ASSERT( input. lookahead. size( )); 
               ASSERT( input. lookahead. back( ). iswellformed( ));
            }
         }

#ifdef MAPH_DEBUG 
         std::cout << "recovery = " << recovery << "\n";
         if( input. lookahead. size( ))
         {
            std::cout << "lookahead = ";
            std::cout << input. lookahead. front( ) << "\n";
         }
#endif

         if( ignoredtokens >= recoverlength ) 
         {
            // That was it. Game over. We lost.

            input. lookahead. clear( );
            input. lookahead. push_front( tkn__recover );
            return;
         }

         if( isstartlookahead( entry, input ))
         {
            // We reached a lookahead symbol of the grammar. 
            // We admit our defeat. 

            return;
         } 

         while( states. size( ) > recovery + 1 )
         {
            states. pop_back( );
            parsestack. pop_back( ); 
         }

         input. lookahead. push_front( token( tkn__recover ));
         actions = decideaction( states. back( ), input );
         input. lookahead. pop_front( );

         ASSERT( actions. size( ) == 1 && actions. front( ) > 0 );
         actions. front( ) -= 10000;
       
         states. push_back( actions. front( ));
         parsestack. push_back( token( tkn__recover ));

         actions = decideaction( states. back( ), input );
     
         ASSERT( actions. size( ) == 1 && actions. front( ) > 0 );
         actions. front( ) -= 10000;

#ifdef MAPH_DEBUG
         std::cout << "recovering into state " << actions. front( );
         std::cout << " using token " << input. lookahead. front( ) << "\n";
#endif

         states. push_back( actions. front( ));
         parsestack. splice( parsestack. end( ),
                             input. lookahead, input. lookahead. begin( ));

         errorcount = 3;
      }
   }
}


